{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Medical Image Classification: Hello World Deep Learning Tutorial\n",
    "\n",
    "### Prepare data using the MD.ai python client, train using Keras\n",
    "\n",
    "This is a high-level introduction into practical machine learning for purposes of medical image classification. The goal of this tutorial is to build a deep learning classifier to accurately differentiate between chest and abdominal X-rays. The model is trained using 75 images de-identified images obtained from Open-i.\n",
    "\n",
    "Original github repo this is based on: https://github.com/ImagingInformatics/machine-learning\n",
    "\n",
    "MD.ai annotator project URL: https://public.md.ai/annotator/project/PVq9raBJ\n",
    "\n",
    "**How to use on Colab: in the menu, go to Runtime -> Change runtime type -> switch to Python 3, and turn on GPU.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import the `mdai` library\n",
    "\n",
    "On Colab, run the block below to install the `mdai` client library into your python environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install --upgrade --quiet mdai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mdai"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create an `mdai` client\n",
    "\n",
    "The mdai client requires an access token, which authenticates you as the user. To create a new token or select an existing token, navigate to the \"Personal Access Tokens\" tab on your user settings page at the specified MD.ai domain (e.g., public.md.ai).\n",
    "\n",
    "**Important: keep your access tokens safe. Do not ever share your tokens.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mdai_client = mdai.Client(domain='public.md.ai', access_token='')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define project\n",
    "\n",
    "Define a project you have access to by passing in the project id. The project id can be found in the URL in the following format: `https://public.md.ai/annotator/project/{project_id}`.\n",
    "\n",
    "For example, `project_id` would be `PVq9raBJ` for `https://public.md.ai/annotator/project/PVq9raBJ`.\n",
    "\n",
    "Specify optional `path` as the data directory (if left blank, will default to current working directory)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = mdai_client.project('PVq9raBJ', path='data')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set label ids\n",
    "\n",
    "Selected label ids must be explicitly set by `Project#set_label_ids` method in order to prepare datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p.show_label_groups_info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_ids = ['L_yxv', 'L_dyy']\n",
    "p.set_label_ids(label_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the *Training* and *Validation* datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p.show_datasets_info() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create training dataset \n",
    "train_dataset = p.get_dataset_by_name('TRAIN')\n",
    "train_dataset.prepare() \n",
    "train_image_ids = train_dataset.get_image_ids()\n",
    "\n",
    "# create the validation dataset \n",
    "val_dataset = p.get_dataset_by_name('VAL')\n",
    "val_dataset.prepare()\n",
    "val_image_ids = val_dataset.get_image_ids()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Display a few images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize a few train images \n",
    "vis.display_images(train_image_ids[:2], cols=2)\n",
    "vis.display_images(val_image_ids[:2], cols=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use Keras for training and validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import applications\n",
    "from keras.models import Model, Sequential\n",
    "from keras.layers import Dropout, Flatten, Dense, GlobalAveragePooling2D\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define model parameters \n",
    "\n",
    "img_width = 256\n",
    "img_height = 256\n",
    "epochs = 20\n",
    "\n",
    "params = {\n",
    "    'dim': (img_width, img_height),\n",
    "    'batch_size': 5,\n",
    "    'n_classes': 2,\n",
    "    'n_channels': 3,\n",
    "    'shuffle': True,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transfer Learning \n",
    "# Use the InceptionV3 pre-trained model as base model \n",
    "\n",
    "base_model = applications.InceptionV3(weights='imagenet', include_top=False, input_shape=(img_width, img_height, 3))\n",
    "model_top  = Sequential()\n",
    "model_top.add(GlobalAveragePooling2D(input_shape=base_model.output_shape[1:], data_format=None))\n",
    "model_top.add(Dense(256, activation='relu'))\n",
    "model_top.add(Dropout(0.5))\n",
    "model_top.add(Dense(2, activation='softmax')) \n",
    "\n",
    "model = Model(inputs=base_model.input, outputs=model_top(base_model.output))\n",
    "\n",
    "model.compile(optimizer=Adam(lr=0.0001, beta_1=0.9, beta_2=0.999, epsilon=1e-08,decay=0.0), \n",
    "              loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "train_generator = utils.DataGenerator(train_dataset, **params)\n",
    "val_generator = utils.DataGenerator(val_dataset, **params)\n",
    "\n",
    "# Set callback functions to early stop training and save the best model so far\n",
    "callbacks = [\n",
    "    EarlyStopping(monitor='val_loss', patience=2, verbose=2),\n",
    "    ModelCheckpoint(filepath='best_model.h5', monitor='val_loss', save_best_only=True, verbose=2)\n",
    "]\n",
    "\n",
    "history = model.fit_generator(\n",
    "            generator=train_generator,\n",
    "            epochs=epochs,\n",
    "            callbacks=callbacks,\n",
    "            verbose=1,            \n",
    "            validation_data=val_generator,\n",
    "            use_multiprocessing=True, \n",
    "            workers=6)         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "print(history.history.keys())\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(history.history['acc'], 'orange', label='Training accuracy')\n",
    "plt.plot(history.history['val_acc'], 'blue', label='Validation accuracy')\n",
    "plt.plot(history.history['loss'], 'red', label='Training loss')\n",
    "plt.plot(history.history['val_loss'], 'green', label='Validation loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the *Test* dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = p.get_dataset_by_name('TEST')\n",
    "test_dataset.prepare()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights('best_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from skimage.transform import resize\n",
    "\n",
    "for image_id in test_dataset.image_ids: \n",
    "    \n",
    "    image = vis.load_dicom_image(image_id, to_RGB=True)\n",
    "    plt.figure()\n",
    "    plt.imshow(image)\n",
    "    \n",
    "    image = resize(image, (img_width, img_height,3))\n",
    "    x = np.expand_dims(image, axis=0)\n",
    "    y_prob = model.predict(x) \n",
    "    y_classes = y_prob.argmax(axis=-1)\n",
    "    title = 'Pred: ' + test_dataset.class_id_to_class_text(y_classes[0]) + ', prob:' + str(round(y_prob[0][y_classes[0]], 3))\n",
    "    plt.title(title)\n",
    "    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
